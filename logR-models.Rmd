---
title: "3 Loan Models"
author: "HP"
date: "2024-01-31"
output: html_document
---
### Loading packages

```{r warning=FALSE, include=FALSE}
library(readxl)
library(dplyr)
library(data.table)
library(xtable)
library(randomcoloR)
library(gridExtra)
library(caret)
library(rpart.plot)
library(randomForest)
library(xgboost)
library(MASS)
library(pls)
library(R.oo)
library(DiagrammeR)
library(rsvg)


set.seed(31)
```

### Data Loading and exploration

#Read data:
```{r}
d = read_excel('data/NBFC Loan Transaction Data.xlsx')
head(d)
```

#Clean data and remove columns:
```{r}
d_clean = d[,-c(1,2,5,6,11,12,19,27,29,30,34,49,50,51,52)]
d_clean$FORECLOSURE = as.factor(d_clean$FORECLOSURE)
d_clean = na.omit(d_clean)
head(d_clean)
print(length(d_clean$FORECLOSURE))
```

```{r}
d3 = data.frame(d_clean)
d3$FORECLOSURE = as.factor(d3$FORECLOSURE)
d3$PRODUCT = as.factor(d3$PRODUCT)
d4 = subset(d3,select = -FORECLOSURE)
d4_num = subset(d4,select = -PRODUCT)
head(d4)
pca_d4 <- prcomp(t(d4_num), scale = TRUE, center = TRUE)

d_full = data.frame(d3)
d_full_num = subset(d_full,select = -PRODUCT)
head(d_full_num)

d_5 = data.frame(pca_d4$rotation[, 1:5],d3$FORECLOSURE)
names(d_5)[names(d_5) == 'd3.FORECLOSURE'] <- 'FORECLOSURE'

d_10 = data.frame(pca_d4$rotation[, 1:10],d3$FORECLOSURE)
names(d_10)[names(d_10) == 'd3.FORECLOSURE'] <- 'FORECLOSURE'

# head(d_5)
# head(d_10)
```
## Tuning and Data Rotation
## Logistic variable selection

```{r}
# LOGISTIC REGRESSION, VARIABLES FROM TREES ## NO DATA ROTATION
lambda <- seq(.3,.8,.02)
lambda_test <- NULL



for (l in lambda){

modlogistic1 <- glm(FORECLOSURE ~ PRODUCT + DIFF_ORIGINAL_CURRENT_INTEREST_RATE + NET_DISBURSED_AMT + 
                      DIFF_ORIGINAL_CURRENT_TENOR + ORIGNAL_INTEREST_RATE, family = binomial(link = "logit"), data= d_train)

log1_tr_pred  <-  predict(modlogistic1, d_train[,-ncol(d_train)],type="response")
log1_tr_pred  <- as.factor(ifelse(log1_tr_pred <l, 0, 1))
log1_tr_accuracy <- (sum(log1_tr_pred == d_train$FORECLOSURE)/length(d_train$FORECLOSURE))
log1_tr_sensitivity <- sensitivity(log1_tr_pred, d_train$FORECLOSURE)
log1_tr_specificity <- specificity(log1_tr_pred, d_train$FORECLOSURE)

log1_te_pred  <-  predict(modlogistic1, d_test[,-ncol(d_test)],type="response")
log1_te_pred <- as.factor(ifelse(log1_te_pred  <l,0,1))
log1_te_accuracy <- (sum(log1_te_pred == d_test$FORECLOSURE))/length(d_test$FORECLOSURE)
log1_te_sensitivity <- sensitivity(log1_te_pred, d_test$FORECLOSURE)

log1_te_specificity <- specificity(log1_te_pred, d_test$FORECLOSURE)


lambda_test <- rbind(lambda_test, c(l, log1_tr_accuracy, log1_tr_sensitivity, log1_tr_specificity, log1_te_accuracy, log1_te_sensitivity, log1_te_specificity))

}

colnames(lambda_test) = c('lambda', 'training accuracy', 'training sensitivity', 'training specificity', 'testing accuracy', 'testing sensitivity', 'testing specificity')
lambda_test <- data.frame(lambda_test)

```

```{r}
testing_metrics <- lambda_test[,c(1, 5:7)]
data_long <- reshape2::melt(testing_metrics, id = "lambda") 


gfg_plot <- ggplot(data_long,             
               aes(x = lambda, 
                   y = value, 
                   color = variable)) +  geom_line(linewidth=1) +theme_bw()

gfg_plot
```

```{r}
# LOGISTIC REGRESSION, VARIABLES FROM TREES ## NO DATA ROTATION
lambda2 <- seq(.3,.8,.02)
lambda_test2 <- NULL

d3_0 <- (d3[(d3$FORECLOSURE==0),])
d3_1 <- (d3[(d3$FORECLOSURE==1),])

n <- nrow(d3)
n1 <- nrow(d3_1)
n0 <- nrow(d3_0)

B=100

for (b in B){

### randomly select n1 observations as a new training subset in each loop

  ## MATCH 0 and 1 data points
  picked1 = sample(seq_len(nrow(d3_0)),size = nrow(d3_1))
  d3_0_picked =d3_0[picked1,]
  
  d_even <- rbind(d3_0_picked, d3_1)
  rownames(d_even) = seq(length=nrow(d_even))
  
  sample_size = floor(.8*nrow(d_even))
  
  picked = sample(seq_len(nrow(d_even)),size = sample_size)
  
  d_even_train =d_even[picked,]
  d_even_test =d_even[-picked,]
  
  
  for (l in lambda){
  
    modlogistic2 <- glm(FORECLOSURE ~ PRODUCT + DIFF_ORIGINAL_CURRENT_INTEREST_RATE + NET_DISBURSED_AMT + 
                          DIFF_ORIGINAL_CURRENT_TENOR + ORIGNAL_INTEREST_RATE, family = binomial(link = "logit"), data= d_even_train)
    
    log1_tr_pred2  <-  predict(modlogistic2, d_even_train[,-ncol(d_even_train)],type="response")
    log1_tr_pred2  <- as.factor(ifelse(log1_tr_pred2 <l, 0, 1))
    log1_tr_accuracy2 <- (sum(log1_tr_pred2 == d_even_train$FORECLOSURE)/length(d_even_train$FORECLOSURE))
    log1_tr_sensitivity2 <- sensitivity(log1_tr_pred2, d_even_train$FORECLOSURE)
    log1_tr_specificity2 <- specificity(log1_tr_pred2, d_even_train$FORECLOSURE)
    
    log1_te_pred2  <-  predict(modlogistic2, d_even_test[,-ncol(d_even_test)],type="response")
    log1_te_pred2 <- as.factor(ifelse(log1_te_pred2  <l,0,1))
    log1_te_accuracy2 <- (sum(log1_te_pred2 == d_even_test$FORECLOSURE))/length(d_even_test$FORECLOSURE)
    log1_te_sensitivity2 <- sensitivity(log1_te_pred2, d_even_test$FORECLOSURE)
    
    log1_te_specificity2 <- specificity(log1_te_pred2, d_even_test$FORECLOSURE)
    
    
    lambda_test2 <- rbind(lambda_test2, c(l, log1_te_accuracy2, log1_te_sensitivity2, log1_te_specificity2))

  }}

colnames(lambda_test2) = c('lambda', 'testing accuracy', 'testing sensitivity', 'testing specificity')
lambda_test2 <- data.frame(lambda_test2)
```


```{r}
testing_metrics2 <- lambda_test2
data_long2<- reshape2::melt(testing_metrics2, id = "lambda") 


gfg_plot2 <- ggplot(data_long2,             
               aes(x = lambda, 
                   y = value, 
                   color = variable)) +  geom_line(linewidth=1) + theme_bw()

gfg_plot2
```
```{r}
xtable(testing_metrics2[abs(testing_metrics2$testing.sensitivity-testing_metrics2$testing.specificity) <=.01,])

```



## MONTE CARLO for Logistic


```{r warning=FALSE}

set.seed(0920)

d3_0 <- (d3[(d3$FORECLOSURE==0),])
d3_1 <- (d3[(d3$FORECLOSURE==1),])

n <- nrow(d3)
n1 <- nrow(d3_1)
n0 <- nrow(d3_0)

h = 0.66

### Initialize the TE values for all models in all $B=100$ loops
B <- 100; ### number of loops
TEALL <- NULL

for (b in 1:B){
### randomly select n1 observations as a new training subset in each loop

  ## MATCH 0 and 1 data points
  picked1 = sample(n0,size = n1)
  d3_0_picked =d3_0[picked1,]
  
  d_even <- rbind(d3_0_picked, d3_1)
  rownames(d_even) = seq(length=nrow(d_even))
  
  d_even_num <- subset(d_even, select = -PRODUCT)
  rownames(d_even_num) = seq(length=nrow(d_even_num))
  
  flag <- sample(seq_len(nrow(d_even)),size = nrow(d_even)/5)
  fore_train_temp <- d_even[-flag, ] # Temp training set for CV
  fore_test_temp <- d_even[flag, ] # Temp testing set for CV
  fore_train_temp$FORECLOSURE <- fore_train_temp$FORECLOSURE
  fore_test_temp$FORECLOSURE <- fore_test_temp$FORECLOSURE
  
  fore_train_num_temp <- d_even_num[-flag, ] # Temp training set for CV
  fore_test_num_temp <- d_even_num[flag, ] # Temp testing set for CV
  
  ytrain_num_temp <- fore_train_num_temp$FORECLOSURE
  ytest_num_temp <- fore_test_num_temp$FORECLOSURE
  
  y = ncol(fore_train_temp)
  y_num = ncol(fore_train_num_temp)

  
  ### LOGISTIC USING SELECTION FROM DECISION TREE

  
  modlogistic1 <- glm(FORECLOSURE ~ PRODUCT + PAID_INTEREST + 
                          EMI_DUEAMT + EMI_RECEIVED_AMT + CURRENT_INTEREST_RATE_MAX, 
                      family = binomial(link = "logit"), data= fore_train_temp)
  
  log1_tr_pred  <-  predict(modlogistic1, fore_train_temp[,-y])
  log1_tr_pred  <- as.factor(ifelse(log1_tr_pred <h, 0, 1))
  levels(log1_tr_pred)<-c(0,1)
  log1_tr_accuracy <- (sum(log1_tr_pred == fore_train_temp$FORECLOSURE)/length(fore_train_temp$FORECLOSURE))
  log1_tr_sensitivity <- sum(as.numeric(fore_train_num_temp$FORECLOSURE == log1_tr_pred)*as.numeric(fore_train_num_temp$FORECLOSURE))/sum(as.numeric(fore_train_num_temp$FORECLOSURE))

  
  log1_te_pred  <-  predict(modlogistic1, fore_test_temp[,-y])
  log1_te_pred <- as.factor(ifelse(log1_te_pred  <h,0,1))
  levels(log1_te_pred)<-c(0,1)
  log1_te_accuracy <- (sum(log1_te_pred == fore_test_temp$FORECLOSURE))/length(fore_test_temp$FORECLOSURE)
  log1_te_sensitivity <- sum(as.numeric(fore_test_num_temp$FORECLOSURE == log1_te_pred)*as.numeric(fore_test_num_temp$FORECLOSURE))/sum(as.numeric(fore_test_num_temp$FORECLOSURE))
  
  
  ### LOGISTIC USING SELECTION FROM VARIABLES
  modlogistic2 <- glm( FORECLOSURE ~ DIFF_ORIGINAL_CURRENT_TENOR + DIFF_ORIGINAL_CURRENT_INTEREST_RATE + 
                           ORIGNAL_TENOR + DIFF_CURRENT_INTEREST_RATE_MAX_MIN + CURRENT_INTEREST_RATE_MIN, 
                         family = binomial(link = "logit"), data= fore_train_temp);
  
  log2_tr_pred  <-  predict(modlogistic2, fore_train_temp[,-y])
  log2_tr_pred  <- as.factor(ifelse(log2_tr_pred <h, 0, 1))
  levels(log2_tr_pred)<-c(0,1)
  log2_tr_accuracy <- (sum(log2_tr_pred == fore_train_temp$FORECLOSURE))/length(fore_train_temp$FORECLOSURE)
  log2_tr_sensitivity <- sum(as.numeric(fore_train_num_temp$FORECLOSURE == log2_tr_pred)*as.numeric(fore_train_num_temp$FORECLOSURE))/sum(as.numeric(fore_train_num_temp$FORECLOSURE))
  
  
  log2_te_pred  <-  predict(modlogistic2, fore_test_temp[,-y])
  log2_te_pred <- as.factor(ifelse(log2_te_pred  < h,0,1))
  levels(log2_te_pred)<-c(0,1)
  log2_te_accuracy <- (sum(log2_te_pred == fore_test_temp$FORECLOSURE))/length(fore_test_temp$FORECLOSURE)
  log2_te_sensitivity <- sum(as.numeric(fore_test_num_temp$FORECLOSURE == log2_te_pred)*as.numeric(fore_test_num_temp$FORECLOSURE))/sum(as.numeric(fore_test_num_temp$FORECLOSURE))

   
  ### Stepwise Selection

  scope.model<- glm(as.factor(FORECLOSURE) ~ 1, family = binomial(link = "logit"), data= fore_train_num_temp)
  base.model<- glm(as.factor(FORECLOSURE) ~ ., family = binomial(link = "logit"), data= fore_train_num_temp)
  
  step.model <- stepAIC(base.model, direction = 'both', scope = scope.model, trace=FALSE)

  step_tr_pred <- predict(step.model, fore_train_num_temp[,-y], type='response')
  step_tr_pred <- as.factor(ifelse(step_tr_pred<h,0,1))
  levels(step_tr_pred)<-c(0,1)
  step_tr_accuracy <- (sum(step_tr_pred == ytrain_num_temp)/length(ytrain_num_temp))
  step_tr_sensitivity <- sum(as.numeric(fore_train_num_temp$FORECLOSURE == step_tr_pred)*as.numeric(fore_train_num_temp$FORECLOSURE))/sum(as.numeric(fore_train_num_temp$FORECLOSURE))
  
  step_te_pred <- predict(step.model, fore_test_num_temp[,-y])
  step_te_pred <- as.factor(ifelse(step_te_pred<h,0,1))
  levels(step_te_pred)<-c(0,1)
  step_te_accuracy <- (sum(step_te_pred == ytest_num_temp)/length(ytest_num_temp))
  step_te_sensitivity <- sum(as.numeric(fore_test_num_temp$FORECLOSURE == step_te_pred)*as.numeric(fore_test_num_temp$FORECLOSURE))/sum(as.numeric(fore_test_num_temp$FORECLOSURE))

  TEALL = rbind(TEALL, c(log1_tr_accuracy, log1_tr_sensitivity, log1_te_accuracy, log1_te_sensitivity, log2_tr_accuracy,
                log2_tr_sensitivity, log2_te_accuracy, log2_te_sensitivity, step_tr_accuracy, step_tr_sensitivity,
                step_te_accuracy, step_te_sensitivity))
  # ridge_tr_accuracy, ridge_tr_sensitivity, ridge_te_accuracy, ridge_te_sensitivity
  # , 'ridge_tr_accuracy', 'ridge_tr_sensitivity', 'ridge_te_accuracy', 'ridge_te_sensitivity
  ###
}



### END ###

dim(TEALL);

colnames(TEALL) <- c('log1_tr_accuracy', 'log1_tr_sensitivity', 'log1_te_accuracy', 'log1_te_sensitivity', 'log2_tr_accuracy', 'log2_tr_sensitivity', 'log2_te_accuracy', 'log2_te_sensitivity', 'step_tr_accuracy', 'step_tr_sensitivity',
                'step_te_accuracy', 'step_te_sensitivity');
## You can report the sample mean/variances of the testing errors so as to compare these models
mean <- apply(TEALL, 2, mean)
median <- apply(TEALL,2,median)
variance <- apply(TEALL, 2, var)
CI <- round(1.96 * (mean/sqrt(variance)),5)

final_frame <- rbind(mean, median, variance, CI)
xtable(t(data.frame(final_frame)), digits=5)
```


```{r}
dim(TEALL); ### This should be a Bx10 matrices
TEALL_test <- TEALL[1:88,]

colnames(TEALL_test) <- c('log1_tr_accuracy', 'log1_tr_sensitivity', 'log1_te_accuracy', 'log1_te_sensitivity', 'log2_tr_accuracy', 
                'log2_tr_sensitivity', 'log2_te_accuracy', 'log2_te_sensitivity', 'step_tr_accuracy', 'step_tr_sensitivity',
                'step_te_accuracy', 'step_te_sensitivity', 'ridge_tr_accuracy', 'ridge_tr_sensitivity', 'ridge_te_accuracy',
                'ridge_te_sensitivity');
## You can report the sample mean/variances of the testing errors so as to compare these models
mean <- apply(TEALL_test, 2, mean)
median <- apply(TEALL_test,2,median)
variance <- apply(TEALL_test, 2, var)
CI <- round(1.96 * (mean/sqrt(var)),5)

final_frame <- rbind(mean, median, var, CI)
t(final_frame)
```

