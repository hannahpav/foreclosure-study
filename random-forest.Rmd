### Loading packages

```{r warning=FALSE, include=FALSE}
library(readxl)
library(dplyr)
library(data.table)
library(xtable)
library(randomcoloR)
library(gridExtra)
library(caret)
library(rpart.plot)
library(randomForest)
library(xgboost)
library(MASS)
library(pls)
library(R.oo)
library(DiagrammeR)
library(rsvg)
library(outliers)
library(reshape2)

set.seed(31)
```

### Data Loading and exploration

#Read data:
```{r}
d = read_excel('data/NBFC Loan Transaction Data.xlsx')
head(d)
```

#Clean data and remove columns:
```{r}
d_clean = d[,-c(1,2,5,6,11,12,19,27,29,30,34,49,50,51,52)]
d_clean$FORECLOSURE = as.factor(d_clean$FORECLOSURE)
d_clean = na.omit(d_clean)
head(d_clean)
print(length(d_clean$FORECLOSURE))
```

```{r}
d3 = data.frame(d_clean)
d3$FORECLOSURE = as.factor(d3$FORECLOSURE)
d4 = subset(d3,select = -FORECLOSURE)
d4_num = subset(d4,select = -PRODUCT)
pca_d4 <- prcomp(t(d4_num), scale = TRUE, center = TRUE)

d_full = data.frame(d3)
d_full_num = subset(d_full,select = -PRODUCT)


d3_0 <- (d3[(d3$FORECLOSURE==0),])
d3_1 <- (d3[(d3$FORECLOSURE==1),])



```


#Find best hyperparameter for sensitivity randomforest, ntree: https://machinelearningmastery.com/tune-machine-learning-algorithms-in-r/
```{r}
B=2
ntree_ALL <- NULL

for(b in 1:B){

picked1 = sample(seq_len(nrow(d3_0)),size = nrow(d3_1))
d3_0_picked =d3_0[picked1,]

d_even <- rbind(d3_0_picked, d3_1)
rownames(d_even) = seq(length=nrow(d_even))

d_even_num <- subset(d_even, select = -PRODUCT)
rownames(d_even_num) = seq(length=nrow(d_even_num))

data = d_even_num
p = 0.1
n = nrow(d_even)
accrf = numeric(10)
senrf = numeric(10)
nc = 1
f = 10

Xp = seq(from=100, to=1000,by = 100)

for (p in Xp){
  cacc = 0
  csen = 0
  
for (i in seq(from=1, to=n-n/f,by = n/f)) {
    # Exclude the i-th observation
    data_subset = data[-(i:(i+n/f)), ]
    
    # Fit RF model
    rf_model = randomForest(FORECLOSURE ~ ., data = data_subset, type = 'classification', ntree = p)
    
    # Make prediction for the excluded observation
    y_pred = predict(rf_model, newdata = data[i:(i+n/f), , drop = FALSE])
    
    # Calculate accuracy and sensitivity
    cacc = sum(as.numeric(data$FORECLOSURE[i:(i+n/f)] == y_pred)) + cacc
    csen = sum(as.numeric(data$FORECLOSURE[i:(i+n/f)] == y_pred)*as.numeric(data$FORECLOSURE[i:(i+n/f)]))+csen
}
  
  accrf[nc] = cacc/n
  senrf[nc] = csen/sum(as.numeric(data$FORECLOSURE))
  nc = nc+1
}

ntree_ALL <- rbind(ntree_ALL, c(p, mean(accrf[nc]), mean(senrf[nc])  ))

}
```

```{r}
rf_tree_frame <- cbind(data.frame('ntrees' = Xp, "accuracy" = accrf), 'sensitivity' = senrf)
long_ntree <- reshape::melt(rf_tree_frame, id = 'ntrees')

ntree_plot <- ggplot(long_ntree,             
               aes(x = ntrees, 
                   y = value, 
                   color = variable )) +  geom_line(linewidth=1) + 
  ggtitle('Cross validation accuracy overview for randomForest')

ntree_plot
```


## Summary Function

```{r}
# Define a summary function for classification evaluation
mySummary <- function(data, lev = NULL, model = NULL) {
  # Compute the confusion matrix
  cm <- caret::confusionMatrix(data[, "pred"], data[, "obs"])
  
  # Compute the metrics
  out <- c(
    Accuracy = cm$overall["Accuracy"],
    Kappa = cm$overall["Kappa"],
    Sensitivity = cm$byClass["Sensitivity"],
    Specificity = cm$byClass["Specificity"],
    Pos_Pred_Value = cm$byClass["Pos Pred Value"],
    Neg_Pred_Value = cm$byClass["Neg Pred Value"],
    Precision = cm$byClass["Pos Pred Value"],
    Recall = cm$byClass["Sensitivity"],
    F1 = 2 * ((cm$byClass["Pos Pred Value"] * cm$byClass["Sensitivity"]) / (cm$byClass["Pos Pred Value"] + cm$byClass["Sensitivity"]))
  )
# Compute AUC if the probabilities of the positive class are available
  if ("Class1" %in% colnames(data)) {
    roc_obj <- pROC::roc(data$obs, data[["Class1"]])
    out["AUC"] <- pROC::auc(roc_obj)
  }
  out
}

# Create the train control
myControl <- trainControl(
  method = "cv", 
  number = 5, 
  summaryFunction = mySummary, 
  classProbs = TRUE,  # Set TRUE to get AUC
  savePredictions = "all"
)
```

```{r}
B=2

for(b in 1:B){

picked1 = sample(seq_len(nrow(d3_0)),size = nrow(d3_1))
d3_0_picked =d3_0[picked1,]

d_even <- rbind(d3_0_picked, d3_1)
rownames(d_even) = seq(length=nrow(d_even))

d_even_num <- subset(d_even, select = -PRODUCT)
rownames(d_even_num) = seq(length=nrow(d_even_num))

data = d_even_num
levels(data$FORECLOSURE) <- c('no','yes')
p = 0.1
n = nrow(data)

rf_frame = NULL

Xp = seq(from=100, to=1000,by = 100)

for (p in Xp){

  
model_rf <- caret::train(x = data[,-ncol(data)], 
               y = data$FORECLOSURE, 
               ntree = p,
               method = "rf", 
               trControl = myControl,
               metric = "Accuracy.Accuracy",
               )  # or any other metric you want to optimize

average_metrics_rf <- colMeans(model_rf$resample[, c("Accuracy.Accuracy", "Recall.Sensitivity")], 
                            na.rm = TRUE)

rf_frame <- rbind(rf_frame, (c(p, average_metrics_rf[1], average_metrics_rf[2])))

}
                            
```



```{r}

rf_frame_plot <- rf_frame[,2:3]
colnames(rf_frame_plot) <- c('accuracy','sensitivity')
data_long_rf<- cbind('ntrees' = seq(100,1000,100),melt(rf_frame_plot))[,-2]



gfg_plot <- ggplot(data_long_rf,             
               aes(x = ntrees, 
                   y = value, 
                   color = Var2 )) +  geom_line(linewidth=1) + 
  ggtitle('Cross validation accuracy overview for randomForest') +theme_bw()

gfg_plot

xtable(data.frame(rf_frame[which.max(rf_frame[,3]),]))

```


#Find best hyperparameter for sensitivity randomforest, nodesize:

```{r}

B=2

for(b in 1:B){

picked1 = sample(seq_len(nrow(d3_0)),size = nrow(d3_1))
d3_0_picked =d3_0[picked1,]

d_even <- rbind(d3_0_picked, d3_1)
rownames(d_even) = seq(length=nrow(d_even))

d_even_num <- subset(d_even, select = -PRODUCT)
rownames(d_even_num) = seq(length=nrow(d_even_num))

data = d_even_num
levels(data$FORECLOSURE) <- c('no','yes')
p = 0.1
n = nrow(data)

rf_frame_node = NULL

Xnode = seq(from=1, to=20,by = 2)

for (p in Xnode){

  
model_rf_node <- caret::train(FORECLOSURE ~ ., 
               data = data, 
               nodesize = p,
               method = "rf", 
               trControl = myControl,
               metric = "Accuracy.Accuracy",
               )  # or any other metric you want to optimize

average_metrics_rf_node <- colMeans(model_rf_node$resample[, c("Accuracy.Accuracy", "Recall.Sensitivity")], 
                            na.rm = TRUE)

rf_frame_node <- data.frame(rbind(rf_frame_node, (c(p, average_metrics_rf[1], average_metrics_rf[2]))))

}
}
```


#Find best hyperparameter for sensitivity randomforest, mtry:

```{r}
data = d_even_num
levels(data) = c('no','yes')
p = 0.1
n = nrow(d_even)

mtry <- sqrt(ncol(data))
tunegrid <- expand.grid(.mtry=mtry)

rControl <- trainControl(
  method = "repeatedcv", 
  number = 10, 
  repeats = 3,
  summaryFunction = mySummary, 
  classProbs = TRUE,  # Set TRUE to get AUC
  savePredictions = "all",
  search = 'random'
)
  
model_rf_mtry <- caret::train(FORECLOSURE ~ ., 
               data = data, 
               tuneLength=15,
               method = "rf", 
               trControl = rControl,
               metric = "Accuracy.Accuracy",
               )  # or any other metric you want to optimize



```




```{r}

model_rf_mtry_plot <- model_rf_mtry$results[,c(1,2,4)]
colnames(model_rf_mtry_plot) <- c('mtry', 'accuracy','sensitivity')
long_mtry<- reshape::melt(model_rf_mtry_plot, id = 'mtry')



mtry_plot <- ggplot(long_mtry,             
               aes(x = mtry, 
                   y = value, 
                   color = variable )) +  geom_line(linewidth=1) + 
  ggtitle('Cross validation accuracy overview for randomForest') + theme_bw()

mtry_plot
```


### Random Forest with Monte Carlo

```{r warning=FALSE}
## caret decision tree  
## involves cross-fold

### save the TE values for all models in all $B=100$ loops
B= 100; ### number of loops
set.seed(7406); ### You might want to set the seed for randomization

d3_0 <- (d3[(d3$FORECLOSURE==0),])
d3_1 <- (d3[(d3$FORECLOSURE==1),])

n <- nrow(d3)
n1 <- nrow(d3_1)
n0 <- nrow(d3_0)

rf_error <- NULL
top_var_rf = NULL
rf_error2 <- NULL

for (b in 1:B){
  
  
  

  ## MATCH 0 and 1 data points
  picked1 = sample(seq_len(nrow(d3_0)),size = nrow(d3_1))
  d3_0_picked =d3_0[picked1,]
  
  d_even <- rbind(d3_0_picked, d3_1)
  rownames(d_even) = seq(length=nrow(d_even))
  
  d_even_num <- subset(d_even, select = -PRODUCT)
  rownames(d_even_num) = seq(length=nrow(d_even_num))
  
  levels(d_even_num$FORECLOSURE) <- c('No', 'Yes')
  levels(d_even_num$FORECLOSURE) <- c('No', 'Yes')
  
  n <- nrow(d_even)
  n1 <- n/5
  
  flag <- sort(sample(1:n, n1))
  fore_train_temp <- d_even_num[flag, ] # Temp training set for CV
  fore_test_temp <- d_even_num[-flag, ] # Temp testing set for CV
  

  
  model_rf <- caret::train(FORECLOSURE ~ ., 
               data = fore_train_temp, 
               method = "rf", 
               trControl = myControl,
               metric = "Accuracy",
               )  # or any other metric you want to optimize
  
  # Calculate the average metrics
  average_metrics_rf <- colMeans(model_rf$resample[, c("Accuracy.Accuracy", 
               "Recall.Sensitivity")], na.rm = TRUE)
  
  ## Predictions
  pred_tr_rf = predict(model_rf, fore_train_temp)
  pred_te_rf = predict(model_rf, fore_test_temp)


  ## Accuracy
  tr_tree_rf = sum(pred_tr_rf == fore_train_temp$FORECLOSURE)/length(fore_train_temp$FORECLOSURE)
  te_tree_rf = sum(pred_te_rf == fore_test_temp$FORECLOSURE)/length(fore_test_temp$FORECLOSURE)

  ## Sensitivity
  ser_tree_rf = sensitivity(pred_tr_rf, fore_train_temp$FORECLOSURE)
  see_tree_rf = sensitivity(pred_te_rf, fore_train_temp$FORECLOSURE)
  
  # Most important Variables
  best_rf <- model_rf$finalModel

  top_var_rf <- rbind(transpose(data.frame(importance(best_rf, type=2))))
  
  rf_error2 = rbind(rf_error2, c(average_metrics_rf[1], average_metrics_rf[2]))
  rf_error = rbind(rf_error, c(tr_tree_rf, te_tree_rf, ser_tree_rf, see_tree_rf))
}



```


```{r}
colnames(rf_error2) = c('Testing Accuracy', 'Testing Sensitivity')

mean_rf <- round(apply(rf_error2, 2, mean),5)
var_rf <- round(apply(rf_error2, 2, var),5)
CI_rf <- round(1.96 * (mean_rf/sqrt(var_rf)),5)

frame_rf <- rbind(mean_rf, var_rf, CI_rf)
print(frame_rf)
xtable(frame_rf, digits = 5)

colnames(top_var_rf) <- rownames(importance(best_rf, type=2))
word_mean <-round(apply(top_var_rf,2,mean),5)
word_mean <- word_mean[order(word_mean, decreasing = TRUE)]
#xtable(data.frame('freq' = word_mean[1:10]))

par(mar=c(4,4,4,8))
dotchart((word_mean[order(word_mean)]), cex=.4, main = 'MeanDecreaseGini')

# words1 <- (table(unlist(top_5_dt)))
# sorted_words <- words1[order(words1, decreasing =TRUE)]
# print(sorted_words)
#xtable(sorted_words)

#xtable(frame,digits=4)

## printed tree
prp(model_rf$finalModel, type=1,faclen=1, extra=1, digits=5, box.palette=c("Greens"))
```

